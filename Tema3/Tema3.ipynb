{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data', transform=lambda x: np.array(x).flatten(), download=True, train=is_train)\n",
    "\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "\n",
    "    return mnist_data, mnist_labels\n",
    "\n",
    "train_X, train_Y = download_mnist(True)\n",
    "test_X, test_Y = download_mnist(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return np.array(data) / 255\n",
    "\n",
    "def one_hot_encoding(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "train_X = normalize(train_X)\n",
    "test_X = normalize(test_X)\n",
    "train_Y = one_hot_encoding(train_Y, 10)\n",
    "test_Y = one_hot_encoding(test_Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, ratio = 0.2):\n",
    "    split_index = int(X.shape[0] * (1 - ratio))\n",
    "    X_train, X_val = X[:split_index], X[split_index:]\n",
    "    y_train, y_val = y[:split_index], y[split_index:]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyLoss(yM, y):\n",
    "    m = y.shape[0]\n",
    "    result = -np.sum(y * np.log(yM)) / m\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(input_size = 784, hidden_size = 100, output_size = 10):\n",
    "    np.random.seed(42)\n",
    "    w1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    w2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, w1, b1, w2, b2):\n",
    "    z1 = X.dot(w1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = a1.dot(w2) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X, y, z1, a1, a2, w2):\n",
    "    m = y.shape[0]\n",
    "    delta2 = a2 - y\n",
    "    dw2 = (a1.T).dot(delta2) / m\n",
    "    db2 = np.sum(delta2, axis=0) / m\n",
    "    delta1 = delta2.dot(w2.T) * relu_derivative(a1)\n",
    "    dw1 = np.dot(X.T, delta1) / m\n",
    "    db1 = np.sum(delta1, axis=0) / m\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate = 0.01, lambda_reg = 0.001):\n",
    "    w1 -= learning_rate * (dw1 + lambda_reg * w1)\n",
    "    b1 -= learning_rate * db1\n",
    "    w2 -= learning_rate * (dw2 + lambda_reg * w2)\n",
    "    b2 -= learning_rate * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(X, y, w1, b1, w2, b2):\n",
    "    _, _, _, a2 = forward_propagation(X, w1, b1, w2, b2)\n",
    "    predictions = np.argmax(a2, axis=1)\n",
    "    labels = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, val_X, val_y, w1, w2, b1, b2, epochs = 10, batch_size = 64, learning_rate = 0.01, lambda_reg = 0.001):\n",
    "    for epoch in range(epochs):\n",
    "        ind = np.arange(X.shape[0])\n",
    "        np.random.shuffle(ind)\n",
    "        X = X[ind]\n",
    "        y = y[ind]\n",
    "\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "\n",
    "            z1, a1, z2, a2 = forward_propagation(X_batch, w1, b1, w2, b2)\n",
    "            dw1, db1, dw2, db2 = back_propagation(X_batch, y_batch, z1, a1, a2, w2)\n",
    "            w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, learning_rate, lambda_reg)\n",
    "\n",
    "    train_accuracy = compute_accuracy(X, y, w1, b1, w2, b2)\n",
    "    val_accuracy = compute_accuracy(val_X, val_y, w1, b1, w2, b2)\n",
    "    print(f\"Epoch {epoch + 1}: Train accuracy = {train_accuracy * 100:.2f}%, Validation accuracy = {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train accuracy = 97.11%, Validation accuracy = 97.33%\n",
      "Test accuracy: 96.52\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, val_X, val_y = split_data(train_X, train_Y)\n",
    "w1, b1, w2, b2 = initialize_params()\n",
    "\n",
    "w1, b1, w2, b2 = train(train_X, train_Y, val_X, val_y, w1, w2, b1, b2, epochs = 50, batch_size = 64, learning_rate = 0.01, lambda_reg = 0.001)\n",
    "\n",
    "print(\"Test accuracy:\", compute_accuracy(test_X, test_Y, w1, b1, w2, b2) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
